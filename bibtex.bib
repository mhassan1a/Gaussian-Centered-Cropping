@unpublished{RnDHassan,
    abstract = {In the contemporary landscape of computer vision and deep learning (DL), contrastive learning (CL) has emerged as a pivotal self-supervised learning (SSL) framework. CL excels by learning directly from unlabeled data, leveraging fundamental principles of knowledge representation to enable DL models to acquire features that are transferable to downstream tasks. However, the effectiveness of CL methods heavily relies on the implementation of robust image augmentation techniques, especially image cropping. Typically, CL methods use random cropping to generate semantically related views (i.e., positive pairs) that act as self-labels. However, random cropping can introduce false positives, where views from different classes are mistakenly treated as positive pairs, leading to a significant drop in performance. To address this issue, this project introduces Gaussian-Centered Cropping (GCC), a method designed to refine the cropping process, thereby minimizing the occurrence of false positives and enhancing the quality of positive pairs. Experimental results demonstrate that GCC outperforms PyTorchâ€™s RandomCrop by 2.7, 6.7, 9.5, and 12.4 percentage points for crop sizes of 20%, 40%, 60%, and 80%, respectively, while maintaining equivalent computational cost. Furthermore, an enhanced version of GCC, termed Multi-object Gaussian-Centered Cropping (MGCC), is proposed to effectively manage images containing multiple objects.
},
    author = {Hassan, Mohamed},
    year = {2024},
    month = {August},
    note = {SS23 Houben, Wasil supervising}
}
